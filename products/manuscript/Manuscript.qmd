---
title: "Analysis of H-1B Visa Workers Using H-1B LCA Disclosure Data (2020â€“2024)"
author: "Yufei Wu"
format:
  docx:
    toc: false
    number-sections: true
    highlight-style: github
bibliography: ../../assets/dataanalysis-references.bib
csl: ../../assets/american-journal-of-epidemiology.csl
---




The structure below is one possible setup for a manuscript, or a general data analysis project (including the course project). Adjust as needed. 
You don't need to have exactly these sections, but the content covering those sections should be addressed.

This uses MS Word as output format. [See here](https://quarto.org/docs/output-formats/ms-word.html) for more information. You can switch to other formats, like html or pdf. See [the Quarto documentation](https://quarto.org/) for other formats.


```{r, echo=FALSE, message=FALSE}
# load a few R packages
library(here)
library(knitr)
```


**Authors**  

* Yufei Wu$^{1}$ (ORCID: 0009-0003-5051-0623) 


**Author affiliations**  

1. Department of Chemistry, University of Georgia, Athens, GA, USA.


$\land$ Corresponding author: yufeiwu@uga.edu

$\dagger$ Disclaimer: The opinions expressed in this article are the
author's own and don't reflect their employer.


{{< pagebreak >}}



# Summary/Abstract
_Write a summary of your project._


{{< pagebreak >}}


# Introduction 

## General Background Information

H-1B is a nonimmigrant visa category that allows employers to hire foreign workers in specialty occupations, like methematics, engineering, technology, and medical sciences [@H1BVisaProgram2016]. It requires the employee to have a bachelor's degree or equivalent in the specific specialty. Typically, the maximun duration of an H-1B visa is six years.It is the most common work visa in the US. There are 65,000 available H-1B visas each year, with 20,000 additional visas for candidates with a master's or doctorate degree from a U.S. institution. If there are more than 65,000 applications, USCIS will run a lottery to decide who can file an H-1B petition. As USCIS is receiving more and more H-1B registration these years, it's harder for a foreign worker to get an H-1B visa. The Labor Condition Application (LCA) is an application filed by employers to apply for work authorization on behalf of employees as a prerequisite for H-1B [@LaborConditionApplication2025]. The LCA contains essential details such as job title, wage, and location about the proposed H-1B employment. Therefore, analyzing the LCA data can provide some ideas on the H-1B application status.

## Description of data and data source

The data is H1B LCA Disclosure Data (2020-2024) from [Kaggle](https://www.kaggle.com/datasets/zongaobian/h1b-lca-disclosure-data-2020-2024/data). It contains LCA disclosure datasets from U.S. Department of Labor, covering the period from 2020 to 2024. It includes information such as case status, job title, Standard Occupational
Classification (SOC) title, location, and wages.

## Questions/Hypotheses to be addressed

This analysis will primarily focus on certified cases. The key research questions to be examined include:
Distribution Analysis:
What is the distribution of certified cases across various features such as SOC titles, locations, wages, and employer names?
Which SOC titles, states, and employers have the highest and lowest number of certified cases?
Variable Relationships:
How do wages vary across different states, SOC titles, and employers?
Employment Trends and Remote Work Patterns:
How have employment patterns evolved over time?
What trends can be observed in remote work prevalence before and after the pandemic?
Predictive Modeling:
Can a predictive model be developed to estimate wages based on job-related and employer-specific features?
Which factors contribute most significantly to wage determination in certified cases?

To cite other work (important everywhere, but likely happens first in introduction), make sure your references are in the bibtex file specified in the YAML header above and have the right bibtex key. Then you can include like this:

Examples of reproducible research projects can for instance be found in [@mckay2020; @mckay2020a].



{{< pagebreak >}}


# Methods 

The data will be reduced to include obeservations with certified case status and visa class of H-1B. Variable will only include RECEIVED_DATE, SOC_TITLE, EMPLOYER_NAME, EMPLOYER_STATE, WORKSITE_STATE, WAGE_RATE_OF_PAY_FROM, PREVAILING_WAGE.


## Schematic of workflow

Sometimes you might want to show a schematic diagram/figure that was not created with code (if you can do it with code, do it). @fig-schematic is an example of some - completely random/unrelated - schematic that was generated with Biorender.
We store those figures in the `assets` folder.

```{r}
#| label: fig-schematic
#| fig-cap: "A figure that is manually generated and shows some overview/schematic. This has nothing to do with the data, it's just a random one from one of our projects I found and placed here."
#| echo: FALSE
knitr::include_graphics(here("assets","antigen-recognition.png"))
```




## Data aquisition

The dataset used in this analysis was obtained from Kaggle. The data was downloaded in CSV format.

## Data import and cleaning
_Write code that reads in the file and cleans it so it's ready for analysis. Since this will be fairly long code for most datasets, it might be a good idea to have it in one or several R scripts. If that is the case, explain here briefly what kind of cleaning/processing you do, and provide more details and well documented code somewhere (e.g. as supplement in a paper). All materials, including files that contain code, should be commented well so everyone can follow along._

```{r}
# load packages
library(here)
library(dplyr)

# load raw data
LCAraw <- read.csv(here("data", "raw-data", "LCA2020to2024.csv"))

# get the overview of the data
dim(LCAraw)
head(LCAraw)

# clean the data
LCAdata <- LCAraw %>%
  filter(CASE_STATUS == "Certified", VISA_CLASS == "H-1B") %>%
  select(RECEIVED_DATE, SOC_TITLE, EMPLOYER_NAME, EMPLOYER_STATE, WORKSITE_STATE, WAGE_RATE_OF_PAY_FROM, PREVAILING_WAGE)

# take a look at the processed data
head(LCAdata)

# save as rds
save_data_location <- here::here("data","processed-data","LCAdata.rds")
saveRDS(LCAdata, file = save_data_location)


```


## Statistical analysis
_Explain anything related to your statistical analyses._
Various plots will be made to visualize the data. Linear regression will be used to analyze the relationship between variables. Machine learning methods will be used as modeling technique.

{{< pagebreak >}}


# Results

## Exploratory/Descriptive analysis

_Use a combination of text/tables/figures to explore and describe your data. Show the most important descriptive results here. Additional ones should go in the supplement. Even more can be in the R and Quarto files that are part of your project._


@tbl-summarytable shows a summary of the data.

Note the loading of the data providing a **relative** path using the `../../` notation. (Two dots means a folder up). You never want to specify an **absolute** path like `C:\ahandel\myproject\results\` because if you share this with someone, it won't work for them since they don't have that path. You can also use the `here` R package to create paths. See examples of that below. I generally recommend the `here` package.

```{r}
#| label: tbl-summarytable
#| tbl-cap: "Data summary table."
#| echo: FALSE
resulttable=readRDS("../../results/tables/summarytable.rds")
knitr::kable(resulttable)
```



## Basic statistical analysis

_To get some further insight into your data, if reasonable you could compute simple statistics (e.g. simple models with 1 predictor) to look for associations between your outcome(s) and each individual predictor variable. Though note that unless you pre-specified the outcome and main exposure, any "p<0.05 means statistical significance" interpretation is not valid._


@fig-result shows a scatterplot figure produced by one of the R scripts.

```{r}
#| label: fig-result
#| fig-cap: "Height and weight stratified by gender."
#| echo: FALSE
knitr::include_graphics(here("results","figures","height-weight-stratified.png"))
```


## Full analysis

_Use one or several suitable statistical/machine learning methods to analyze your data and to produce meaningful figures, tables, etc. This might again be code that is best placed in one or several separate R scripts that need to be well documented. You want the code to produce figures and data ready for display as tables, and save those. Then you load them here._

Example @tbl-resulttable2 shows a summary of a linear model fit.

```{r}
#| label: tbl-resulttable2
#| tbl-cap: "Linear model fit table."
#| echo: FALSE
resulttable2 = readRDS(here("results","tables","resulttable2.rds"))
knitr::kable(resulttable2)
```


{{< pagebreak >}}


# Discussion

## Summary and Interpretation
_Summarize what you did, what you found and what it means._

## Strengths and Limitations
_Discuss what you perceive as strengths and limitations of your analysis._

## Conclusions
_What are the main take-home messages?_

_Include citations in your Rmd file using bibtex, the list of references will automatically be placed at the end_

This paper [@leek2015] discusses types of analyses. 

These papers [@mckay2020; @mckay2020a] are good examples of papers published using a fully reproducible setup similar to the one shown in this template. 

Note that this cited reference will show up at the end of the document, the reference formatting is determined by the CSL file specified in the YAML header. Many more style files for almost any journal [are available](https://www.zotero.org/styles). You also specify the location of your bibtex reference file in the YAML. You can call your reference file anything you like.


{{< pagebreak >}}

# References



